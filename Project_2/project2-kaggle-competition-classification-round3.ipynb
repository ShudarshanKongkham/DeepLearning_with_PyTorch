{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods, which will be used to get training and validation data loader.\n",
    "\n",
    "You need to write a custom dataset class to load data.\n",
    "\n",
    "**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "    ....\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "def get_data(args1, *args):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # one of the best graphics library for python\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter(log_dir='TFlearning_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading images and labels for the KenyanFood13 challenge.\n",
    "    This class reads a CSV file with columns 'id' and 'class', and loads images stored as '<id>.jpg'\n",
    "    in the specified image root directory. It also supports optional image resizing and transformations.\n",
    "    The train flag is used to split the full dataset into 80% training and 20% validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, image_root, train=True, image_shape=None, transform=None):\n",
    "        \"\"\"\n",
    "        Initialization method.\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        csv_file (str): Path to the CSV file containing image ids and class labels.\n",
    "        \n",
    "        image_root (str): Directory where image files are stored. Images are expected to be named as '<id>.jpg'.\n",
    "        \n",
    "        train (bool): If True, returns 80% of the data for training; if False, returns 20% for validation.\n",
    "        \n",
    "        image_shape (int or tuple or list): [optional] If provided, image will be resized to the given shape.\n",
    "                                            If an integer is provided, images are resized to (image_shape, image_shape).\n",
    "                                            If a tuple/list is provided with one value, it is converted to square dimensions;\n",
    "                                            otherwise, the tuple is used as is.\n",
    "                                            \n",
    "        transform (callable): Transformation function to be applied on the PIL image.\n",
    "        \"\"\"\n",
    "        # Read the CSV file containing the image ids and their class labels\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_root = image_root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Process image_shape parameter\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            elif isinstance(image_shape, (tuple, list)):\n",
    "                assert len(image_shape) in [1, 2], 'Invalid image_shape tuple/list size'\n",
    "                self.image_shape = (image_shape[0], image_shape[0]) if len(image_shape) == 1 else image_shape\n",
    "            else:\n",
    "                raise NotImplementedError(\"image_shape must be an int, tuple, or list\")\n",
    "        else:\n",
    "            self.image_shape = None\n",
    "        \n",
    "        # Create a mapping from class name to integer label\n",
    "        self.classes = sorted(self.data['class'].unique())\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Build the list of samples (each sample is a tuple of image path and numeric label)\n",
    "        full_samples = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            img_id = row['id']\n",
    "            label_str = row['class']\n",
    "            label = self.class_to_idx[label_str]\n",
    "            img_path = os.path.join(self.image_root, f\"{img_id}.jpg\")\n",
    "            full_samples.append((img_path, label))\n",
    "        \n",
    "        # Shuffle the full sample list with a fixed seed for reproducibility and split into train/validation.\n",
    "        random.seed(42)\n",
    "        random.shuffle(full_samples)\n",
    "        n_train = int(0.8 * len(full_samples))\n",
    "        if self.train:\n",
    "            self.samples = full_samples[:n_train]\n",
    "        else:\n",
    "            self.samples = full_samples[n_train:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: Total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For the given index, returns the processed image and its label.\n",
    "        \n",
    "        Parameters:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            image: Processed image.\n",
    "            target (int): Numeric label for the image.\n",
    "        \"\"\"\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Resize image if image_shape is specified\n",
    "        if self.image_shape is not None:\n",
    "            image = TF.resize(image, self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def class_name(self, label):\n",
    "        \"\"\"\n",
    "        Gets the class name corresponding to a numeric label.\n",
    "        \n",
    "        Parameters:\n",
    "            label (int): Numeric label.\n",
    "        \n",
    "        Returns:\n",
    "            str: Class name.\n",
    "        \"\"\"\n",
    "        return self.classes[label]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms():\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess\n",
    "\n",
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms\n",
    "\n",
    "def get_mean_std():\n",
    "    \n",
    "    mean = [0.485, 0.456, 0.406] \n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "def data_loader(dataset, batch_size=16, shuffle=False, num_workers=2): \n",
    "    loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=shuffle)\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# Define the missing data_augmentaaion_preprocess function\n",
    "def data_augmentation_preprocess(mean, std):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root, num_workers=4, data_augmentation=True, image_shape=None, csv_file=None):\n",
    "    \"\"\"\n",
    "    Creates training and validation DataLoaders for the KenyanFood13 dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        data_root (str): Root directory containing your dataset.\n",
    "            Expected structure:\n",
    "                data_root/\n",
    "                    training/\n",
    "                        images/ (training images)\n",
    "                        labels.csv (training labels)\n",
    "                    validation/\n",
    "                        images/ (validation images)\n",
    "                        labels.csv (validation labels)\n",
    "        num_workers (int): Number of worker threads for DataLoader.\n",
    "        data_augmentation (bool): Apply data augmentation on training data if True.\n",
    "        image_shape (int, tuple, or list): Desired image size.\n",
    "        csv_file (str, optional): If provided, use this as CSV file path for training;\n",
    "                                  otherwise, assumes it is located under the respective folder.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_loader, validation_loader)\n",
    "    \"\"\"\n",
    "    # Define paths for training images\n",
    "    train_csv = csv_file or os.path.join(data_root, 'train.csv')\n",
    "    # Assume training images are stored in a folder named 'images'\n",
    "    train_image_root = os.path.join(data_root, 'images')\n",
    "    \n",
    "    # Get normalization parameters and common transformations\n",
    "    mean, std = get_mean_std()  # adjust if your get_mean_std needs additional arguments\n",
    "    common_transforms = image_common_transforms(mean, std)\n",
    "    \n",
    "    if data_augmentation:\n",
    "        train_transforms = data_augmentation_preprocess(mean, std)\n",
    "    else:\n",
    "        train_transforms = common_transforms\n",
    "\n",
    "    # Create the training and validation datasets using the KenyanFood13Dataset class\n",
    "    train_dataset = KenyanFood13Dataset(train_csv, train_image_root, train=True, image_shape=image_shape, transform=train_transforms)\n",
    "    validation_dataset = KenyanFood13Dataset(train_csv, train_image_root, train=False, image_shape=image_shape, transform=common_transforms)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "**Define your configuration here.**\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"/kaggle/input/opencv-pytorch-project-2-classification-round-3\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 21  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration  \n",
    "    epochs_count: int = 10 \n",
    "    init_learning_rate: float = 0.001  # initial learning rate for lr scheduler\n",
    "    decay_rate: float = 0.1  \n",
    "    log_interval: int = 1  # how many batches to wait before logging training status  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = './opencv-pytorch-project-2-classification-round-3/'\n",
    "    csv_file: str = './opencv-pytorch-project-2-classification-round-3/train.csv'\n",
    "    num_workers: int = 2  # number of concurrent processes using to prepare data  \n",
    "    device: str = 'cuda'  \n",
    "    lr_scheduler_patience: int = 5     # Patience (in epochs) for ReduceLROnPlateau scheduler\n",
    "    lr_scheduler_factor: float = 0.3   # LR reduction factor when plateauing\n",
    "    early_stopping_patience: int = 5  # Patience (in epochs) for early stopping\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bhaji',\n",
       " 'chapati',\n",
       " 'githeri',\n",
       " 'kachumbari',\n",
       " 'kukuchoma',\n",
       " 'mandazi',\n",
       " 'masalachips',\n",
       " 'matoke',\n",
       " 'mukimo',\n",
       " 'nyamachoma',\n",
       " 'pilau',\n",
       " 'sukumawiki',\n",
       " 'ugali']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# food_classes = ['Ugali', 'Chapati', 'Mukimo', 'Matoke', 'Kachumbari', 'Sukuma Wiki', 'Nyama Choma', 'Githeri', 'Mandazi', 'Pilau', 'Kebab', 'Samaki', 'Wali']\n",
    "dataset = KenyanFood13Dataset(TrainingConfiguration.csv_file, TrainingConfiguration.data_root, train=False, image_shape=224)\n",
    "food_classes = dataset.classes\n",
    "food_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input, max_prob=True):\n",
    "    \"\"\"\n",
    "    get prediction for batch inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # get probability score using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "    \n",
    "    if max_prob:\n",
    "        # get the max probability\n",
    "        pred_prob = prob.data.max(dim=1)[0]\n",
    "    else:\n",
    "        pred_prob = prob.data\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_target_and_prob(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    get targets and prediction probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_prob = []\n",
    "    targets = []\n",
    "    \n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        \n",
    "        _, prob = prediction(model, device, data, max_prob=False)\n",
    "        \n",
    "        pred_prob.append(prob)\n",
    "        \n",
    "        target = target.numpy()\n",
    "        targets.append(target)\n",
    "        \n",
    "    targets = np.concatenate(targets)\n",
    "    targets = targets.astype(int)\n",
    "    pred_prob = np.concatenate(pred_prob, axis=0)\n",
    "    \n",
    "    return targets, pred_prob\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "\n",
    "**Write the methods or classes to be used for training and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_correct_predictions = 0\n",
    "    # Iterate over test_loader with a tqdm progress bar.\n",
    "    for data, target in tqdm(test_loader, desc=\"Validation\", leave=False):\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        target = target.to(train_config.device)\n",
    "        print(\"Data device:\", data.device)\n",
    "        print(\"Target device:\", target.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        \n",
    "        # Accumulate loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Get predictions from probabilities\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        pred = prob.data.max(dim=1)[1]\n",
    "        \n",
    "        count_correct_predictions += pred.cpu().eq(indx_target).sum().item()\n",
    "\n",
    "    # Average loss over the number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # Compute accuracy over the entire dataset\n",
    "    accuracy = 100. * count_correct_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss, count_correct_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    return test_loss, accuracy / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='final_kenyaFood_classifier.pt'):\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu. \n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return model_path                                 \n",
    "\n",
    "def load_model(model, model_dir='models', model_file_name='final_kenyaFood_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, scheduler=None, early_stopping=None, \n",
    "         system_configuration=SystemConfiguration(), \n",
    "         training_configuration=TrainingConfiguration(), \n",
    "         data_augmentation=True):\n",
    "    \n",
    "    print(\"Step 1: Setting up system configuration...\")\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    print(\"Step 2: Initializing training parameters (batch size, num_workers, epochs)...\")\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    print(\"Step 3: Selecting device...\")\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 4\n",
    "    print(\"  Device selected:\", device)\n",
    "\n",
    "    # Move model to the selected device\n",
    "    model.to(device)\n",
    "    print(\"Model device:\", next(model.parameters()).device)\n",
    "\n",
    "    print(\"Step 4: Creating data loaders...\")\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set,\n",
    "        data_augmentation=data_augmentation\n",
    "    )\n",
    "    print(\"Data loaders created.\")\n",
    "    \n",
    "\n",
    "    print(\"Step 5: Updating training configuration with system-adjusted parameters...\")\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    print(\"Step 6: Sending model to device...\")\n",
    "    model.to(training_configuration.device)\n",
    "    print(\"Model device after update:\", next(model.parameters()).device)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Arrays to track epoch train/test loss and accuracy\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    print(\"Step 7: Performing initial validation...\")\n",
    "    init_val_loss, init_val_accuracy = validate(training_configuration, model, test_loader)\n",
    "    print(\"Initial Test Loss: {:.6f}, Initial Test Accuracy: {:.3f}%\".format(\n",
    "        init_val_loss, init_val_accuracy * 100))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    print(\"Step 8: Starting training loop for {} epochs...\".format(training_configuration.epochs_count))\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        print(\"\\nEpoch [{}/{}] Start\".format(epoch + 1, training_configuration.epochs_count))\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        epoch_train_loss = np.append(epoch_train_loss, train_loss)\n",
    "        epoch_train_acc = np.append(epoch_train_acc, train_acc)\n",
    "        \n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        print(\"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ETA {:.2f}s\".format(\n",
    "            elapsed_time, speed_epoch, speed_batch, eta))\n",
    "\n",
    "        # Validate at set interval\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            print(\"Step 9: Running validation for epoch {}...\".format(epoch + 1))\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            epoch_test_loss = np.append(epoch_test_loss, current_loss)\n",
    "            epoch_test_acc = np.append(epoch_test_acc, current_accuracy)\n",
    "            \n",
    "            # Early stopping check using validation loss\n",
    "            if early_stopping is not None:\n",
    "                early_stopping(current_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping triggered\")\n",
    "                    break\n",
    "\n",
    "            # Scheduler step/update; prefer validation loss for ReduceLROnPlateau\n",
    "            if scheduler is not None:\n",
    "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(current_loss)\n",
    "                    print(\"Bad Epochs: {}\".format(scheduler.num_bad_epochs))\n",
    "                    print(\"Last LR = {}\".format(scheduler._last_lr))\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            # Save the model if loss has improved\n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print(\"Model Improved. Saving the Model...\\n\")\n",
    "                save_model(model, device=training_configuration.device)\n",
    "        \n",
    "    print(\"\\nStep 10: Training complete.\")\n",
    "    print(\"Total time: {:.2f}s, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss), flush=True)\n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "**Define your model in this section.**\n",
    "\n",
    "**You are allowed to use any pre-trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pretrained_resnet18(transfer_learning=True, num_class=13):\n",
    "    resnet = models.resnet18(pretrained=True)\n",
    "    \n",
    "    if transfer_learning:\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    last_layer_in = resnet.fc.in_features\n",
    "    resnet.fc = nn.Linear(last_layer_in, num_class)\n",
    "    \n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: Input: 3x224x224 -> after conv: 32x224x224, then pool: 32x112x112\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 2: 32x112x112 -> 64x112x112, then pool: 64x56x56\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Block 3: 64x56x56 -> 128x56x56, then pool: 128x28x28\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to collapse spatial dimensions\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "**Define those methods or classes, which have  not been covered in the above sections.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, colors, \n",
    "                       loss_legend_loc='upper center', acc_legend_loc='upper left', \n",
    "                       fig_size=(20, 10), sub_plot1=(1, 2, 1), sub_plot2=(1, 2, 2)):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n",
    "    \n",
    "    for i in range(len(train_loss)):\n",
    "        x_train = range(len(train_loss[i]))\n",
    "        x_val = range(len(val_loss[i]))\n",
    "        \n",
    "        min_train_loss = train_loss[i].min()\n",
    "        \n",
    "        min_val_loss = val_loss[i].min()\n",
    "        \n",
    "        plt.plot(x_train, train_loss[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN LOSS ({0:.4})\".format(min_train_loss))\n",
    "        plt.plot(x_val, val_loss[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID LOSS ({0:.4})\".format(min_val_loss))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc=loss_legend_loc)\n",
    "    plt.title('Training and Validation Loss')\n",
    "        \n",
    "    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n",
    "    \n",
    "    for i in range(len(train_acc)):\n",
    "        x_train = range(len(train_acc[i]))\n",
    "        x_val = range(len(val_acc[i]))\n",
    "        \n",
    "        max_train_acc = train_acc[i].max() \n",
    "        \n",
    "        max_val_acc = val_acc[i].max() \n",
    "        \n",
    "        plt.plot(x_train, train_acc[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN ACC ({0:.4})\".format(max_train_acc))\n",
    "        plt.plot(x_val, val_acc[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID ACC ({0:.4})\".format(max_val_acc))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=acc_legend_loc)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    fig.savefig('sample_loss_acc_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, checkpoint_path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "            verbose (bool): If True, prints messages when the validation loss decreases.\n",
    "            delta (float): Minimum change in the validation loss to qualify as an improvement.\n",
    "            checkpoint_path (str): Path to save the best model.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss  # lower loss is better\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"Saves model when validation loss decreases.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=512, out_features=13, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# model = pretrained_resnet18()\n",
    "model = MyCNN()\n",
    "\n",
    "print(model)\n",
    "\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "# optimizer (using Adam)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=train_config.init_learning_rate\n",
    ")\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=train_config.early_stopping_patience, verbose=True)\n",
    "\n",
    "# ReduceLROnPlateau scheduler to decay LR when validation stops improving\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                           factor=train_config.lr_scheduler_factor,\n",
    "                                           patience=train_config.lr_scheduler_patience,\n",
    "                                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setting up system configuration...\n",
      "Step 2: Initializing training parameters (batch size, num_workers, epochs)...\n",
      "Step 3: Selecting device...\n",
      "  Device selected: cuda\n",
      "Model device: cuda:0\n",
      "Step 4: Creating data loaders...\n",
      "Data loaders created.\n",
      "Step 5: Updating training configuration with system-adjusted parameters...\n",
      "Step 6: Sending model to device...\n",
      "Model device after update: cuda:0\n",
      "Step 7: Performing initial validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model, train_loss, train_acc, val_loss, val_acc = main(model, optimizer, \n",
    "                                                       scheduler=scheduler, \n",
    "                                                       early_stopping=early_stopping,\n",
    "                                                       data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Log Link [5 Points]</font>\n",
    "\n",
    "**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n",
    "\n",
    "\n",
    "Note: In light of the recent shutdown of tensorboard.dev, we have updated the submission requirements for your project. Instead of sharing a tensorboard.dev link, you are now required to upload your generated TensorBoard event files directly onto the lab. As an alternative, you may also include a screenshot of your TensorBoard output within your Jupyter notebook. This adjustment ensures that your data visualization and model training efforts are thoroughly documented and accessible for evaluation.\n",
    "\n",
    "You are also welcome (and encouraged) to utilize alternative logging services like wandB or comet. In such instances, you can easily make your project logs publicly accessible and share the link with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "**Share your Kaggle profile link  with us here to score , points in  the competition.**\n",
    "\n",
    "**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n",
    "\n",
    "\n",
    "**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10665762,
     "sourceId": 90936,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
