{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">4. Loss Function</font>\n",
    "\n",
    "Let's see how our loss function should look like.\n",
    "\n",
    "Different from classification and semantic segmentation task, we now have two branches with two independent outputs.\n",
    "\n",
    "At each iteration, we want to know 2 things - how close are the predicted bounding boxes to the target bounding boxes, and whether their labels are predicted correctly.\n",
    "\n",
    "That's why our loss function is represented as a sum of two losses: localization and classification loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "import inspect\n",
    "\n",
    "from detection_loss import DetectionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">class</span> <span class=\"n\">DetectionLoss</span>(<span class=\"n\">nn</span>.<span class=\"n\">Module</span>):\n",
       "    <span class=\"n\">def</span> <span class=\"n\">__init__</span>(<span class=\"nb\">self</span>, <span class=\"n\">num_classes</span>=<span class=\"mi\">2</span>):\n",
       "        <span class=\"n\">super</span>().<span class=\"n\">__init__</span>()\n",
       "        <span class=\"nb\">self</span>.<span class=\"n\">num_classes</span> = <span class=\"n\">num_classes</span>\n",
       "\n",
       "    <span class=\"n\">def</span> <span class=\"n\">forward</span>(<span class=\"nb\">self</span>, <span class=\"n\">loc_preds</span>, <span class=\"n\">loc_targets</span>, <span class=\"n\">cls_preds</span>, <span class=\"n\">cls_targets</span>):\n",
       "        <span class=\"s\">&#39;&#39;&#39;Compute loss between (loc_preds, loc_targets) and (cls_preds, cls_targets).</span>\n",
       "\n",
       "<span class=\"s\">        Args:</span>\n",
       "<span class=\"s\">          loc_preds: (tensor) predicted locations, sized [batch_size, #anchors, 4].</span>\n",
       "<span class=\"s\">          loc_targets: (tensor) encoded target locations, sized [batch_size, #anchors, 4].</span>\n",
       "<span class=\"s\">          cls_preds: (tensor) predicted class confidences, sized [batch_size, #anchors, #classes].</span>\n",
       "<span class=\"s\">          cls_targets: (tensor) encoded target labels, sized [batch_size, #anchors].</span>\n",
       "\n",
       "<span class=\"s\">        loss:</span>\n",
       "<span class=\"s\">          (tensor) loss = SmoothL1Loss(loc_preds, loc_targets) + OHEMLoss(cls_preds, cls_targets).</span>\n",
       "<span class=\"s\">        &#39;&#39;&#39;</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{class} \\PY{n}{DetectionLoss}(\\PY{n}{nn}.\\PY{n}{Module}):\n",
       "    \\PY{n}{def} \\PY{n}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}(\\PY{n+nb}{self}, \\PY{n}{num\\PYZus{}classes}=\\PY{l+m+mi}{2}):\n",
       "        \\PY{n}{super}().\\PY{n}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}()\n",
       "        \\PY{n+nb}{self}.\\PY{n}{num\\PYZus{}classes} = \\PY{n}{num\\PYZus{}classes}\n",
       "\n",
       "    \\PY{n}{def} \\PY{n}{forward}(\\PY{n+nb}{self}, \\PY{n}{loc\\PYZus{}preds}, \\PY{n}{loc\\PYZus{}targets}, \\PY{n}{cls\\PYZus{}preds}, \\PY{n}{cls\\PYZus{}targets}):\n",
       "        \\PY{l+s}{\\PYZsq{}\\PYZsq{}}\\PY{l+s}{\\PYZsq{}Compute loss between (loc\\PYZus{}preds, loc\\PYZus{}targets) and (cls\\PYZus{}preds, cls\\PYZus{}targets).}\n",
       "\n",
       "\\PY{l+s}{        Args:}\n",
       "\\PY{l+s}{          loc\\PYZus{}preds: (tensor) predicted locations, sized [batch\\PYZus{}size, \\PYZsh{}anchors, 4].}\n",
       "\\PY{l+s}{          loc\\PYZus{}targets: (tensor) encoded target locations, sized [batch\\PYZus{}size, \\PYZsh{}anchors, 4].}\n",
       "\\PY{l+s}{          cls\\PYZus{}preds: (tensor) predicted class confidences, sized [batch\\PYZus{}size, \\PYZsh{}anchors, \\PYZsh{}classes].}\n",
       "\\PY{l+s}{          cls\\PYZus{}targets: (tensor) encoded target labels, sized [batch\\PYZus{}size, \\PYZsh{}anchors].}\n",
       "\n",
       "\\PY{l+s}{        loss:}\n",
       "\\PY{l+s}{          (tensor) loss = SmoothL1Loss(loc\\PYZus{}preds, loc\\PYZus{}targets) + OHEMLoss(cls\\PYZus{}preds, cls\\PYZus{}targets).}\n",
       "\\PY{l+s}{        \\PYZsq{}}\\PY{l+s}{\\PYZsq{}\\PYZsq{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "class DetectionLoss(nn.Module):\n",
       "    def __init__(self, num_classes=2):\n",
       "        super().__init__()\n",
       "        self.num_classes = num_classes\n",
       "\n",
       "    def forward(self, loc_preds, loc_targets, cls_preds, cls_targets):\n",
       "        '''Compute loss between (loc_preds, loc_targets) and (cls_preds, cls_targets).\n",
       "\n",
       "        Args:\n",
       "          loc_preds: (tensor) predicted locations, sized [batch_size, #anchors, 4].\n",
       "          loc_targets: (tensor) encoded target locations, sized [batch_size, #anchors, 4].\n",
       "          cls_preds: (tensor) predicted class confidences, sized [batch_size, #anchors, #classes].\n",
       "          cls_targets: (tensor) encoded target labels, sized [batch_size, #anchors].\n",
       "\n",
       "        loss:\n",
       "          (tensor) loss = SmoothL1Loss(loc_preds, loc_targets) + OHEMLoss(cls_preds, cls_targets).\n",
       "        '''\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(data=inspect.getsource(DetectionLoss)[:797])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4.1. Localization Loss</font>\n",
    "\n",
    "For localization loss, we choose Smooth L1-loss, following [Faster R-CNN paper](https://arxiv.org/pdf/1506.01497.pdf).\n",
    "\n",
    "It was invented as a solution for bounding box regression problem that L2 loss suffers from, as it is sensitive to outliers.\n",
    "\n",
    "Smooth L1-loss can be interpreted as a combination of L1-loss and L2-loss.\n",
    "\n",
    "It behaves as L1-loss when the absolute value of the argument is high, and like L2-loss when the absolute value of the argument is close to zero.\n",
    "\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2020/03/c3-w8-l1l2smoothl1.png' align='middle'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"w\">        </span><span class=\"n\">pos</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_targets</span><span class=\"w\"> </span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\">  </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">N,#anchors</span><span class=\"o\">]</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">num_pos</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">pos</span><span class=\"p\">.</span><span class=\"n\">long</span><span class=\"p\">().</span><span class=\"nf\">sum</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">keepdim</span><span class=\"o\">=</span><span class=\"k\">True</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"w\">        </span><span class=\"n\">mask</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">pos</span><span class=\"p\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">).</span><span class=\"n\">expand_as</span><span class=\"p\">(</span><span class=\"n\">loc_preds</span><span class=\"p\">)</span><span class=\"w\">  </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">N,#anchors,4</span><span class=\"o\">]</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">masked_loc_preds</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">loc_preds</span><span class=\"o\">[</span><span class=\"n\">mask</span><span class=\"o\">]</span><span class=\"p\">.</span><span class=\"k\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"p\">)</span><span class=\"w\">  </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">#pos,4</span><span class=\"o\">]</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">masked_loc_targets</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">loc_targets</span><span class=\"o\">[</span><span class=\"n\">mask</span><span class=\"o\">]</span><span class=\"p\">.</span><span class=\"k\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">4</span><span class=\"p\">)</span><span class=\"w\">  </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"o\">[</span><span class=\"n\">#pos,4</span><span class=\"o\">]</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">loc_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">smooth_l1_loss</span><span class=\"p\">(</span><span class=\"n\">masked_loc_preds</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">masked_loc_targets</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"s1\">&#39;none&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">loc_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">loc_loss</span><span class=\"p\">.</span><span class=\"nf\">sum</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"w\"> </span><span class=\"n\">num_pos</span><span class=\"p\">.</span><span class=\"nf\">sum</span><span class=\"p\">().</span><span class=\"nc\">float</span><span class=\"p\">()</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{+w}{        }\\PY{n}{pos}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}targets}\\PY{+w}{ }\\PY{o}{\\PYZgt{}}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{+w}{  }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{o}{[}\\PY{n}{N,\\PYZsh{}anchors}\\PY{o}{]}\n",
       "\\PY{+w}{        }\\PY{n}{num\\PYZus{}pos}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{pos}\\PY{p}{.}\\PY{n}{long}\\PY{p}{(}\\PY{p}{)}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{keepdim}\\PY{o}{=}\\PY{k}{True}\\PY{p}{)}\n",
       "\n",
       "\\PY{+w}{        }\\PY{n}{mask}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{pos}\\PY{p}{.}\\PY{n}{unsqueeze}\\PY{p}{(}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{.}\\PY{n}{expand\\PYZus{}as}\\PY{p}{(}\\PY{n}{loc\\PYZus{}preds}\\PY{p}{)}\\PY{+w}{  }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{o}{[}\\PY{n}{N,\\PYZsh{}anchors,4}\\PY{o}{]}\n",
       "\\PY{+w}{        }\\PY{n}{masked\\PYZus{}loc\\PYZus{}preds}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{loc\\PYZus{}preds}\\PY{o}{[}\\PY{n}{mask}\\PY{o}{]}\\PY{p}{.}\\PY{k}{view}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{+w}{  }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{o}{[}\\PY{n}{\\PYZsh{}pos,4}\\PY{o}{]}\n",
       "\\PY{+w}{        }\\PY{n}{masked\\PYZus{}loc\\PYZus{}targets}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{loc\\PYZus{}targets}\\PY{o}{[}\\PY{n}{mask}\\PY{o}{]}\\PY{p}{.}\\PY{k}{view}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{+w}{  }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{o}{[}\\PY{n}{\\PYZsh{}pos,4}\\PY{o}{]}\n",
       "\\PY{+w}{        }\\PY{n}{loc\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{F}\\PY{p}{.}\\PY{n}{smooth\\PYZus{}l1\\PYZus{}loss}\\PY{p}{(}\\PY{n}{masked\\PYZus{}loc\\PYZus{}preds}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{masked\\PYZus{}loc\\PYZus{}targets}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{reduction}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}none\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{n}{loc\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{loc\\PYZus{}loss}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{+w}{ }\\PY{o}{/}\\PY{+w}{ }\\PY{n}{num\\PYZus{}pos}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{p}{.}\\PY{n+nc}{float}\\PY{p}{(}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "        pos = cls_targets > 0  # [N,#anchors]\n",
       "        num_pos = pos.long().sum(1, keepdim=True)\n",
       "\n",
       "        mask = pos.unsqueeze(2).expand_as(loc_preds)  # [N,#anchors,4]\n",
       "        masked_loc_preds = loc_preds[mask].view(-1, 4)  # [#pos,4]\n",
       "        masked_loc_targets = loc_targets[mask].view(-1, 4)  # [#pos,4]\n",
       "        loc_loss = F.smooth_l1_loss(masked_loc_preds, masked_loc_targets, reduction='none')\n",
       "        loc_loss = loc_loss.sum() / num_pos.sum().float()\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(data=inspect.getsource(DetectionLoss)[962:1420])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4.2. Classification Loss</font>\n",
    "\n",
    "As classification loss, we use Cross Entropy Loss as the most popular loss for classification task.\n",
    "\n",
    "It should be noted, that class imbalance is a very problematic issue for single-stage detectors.\n",
    "This is because most locations in an image are negatives, that can be easily classified by the detector as background.\n",
    "\n",
    "We want out network to train on hard examples with positives, which constitute only a small part of all of the locations.\n",
    "\n",
    "There are different methods on how to deal with that issue. We choose to use Online Hard Example Mining (OHEM) strategy.\n",
    "It finds hard examples in the batch with the greatest loss values and back-propagates the loss computed over the selected instances.\n",
    "The amount of hard examples correlates with the number of positive examples and is often chosen as `3:1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"w\">       </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"k\">Compute</span><span class=\"w\"> </span><span class=\"nf\">max</span><span class=\"w\"> </span><span class=\"n\">conf</span><span class=\"w\"> </span><span class=\"n\">across</span><span class=\"w\"> </span><span class=\"n\">batch</span><span class=\"w\"> </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">hard</span><span class=\"w\"> </span><span class=\"n\">negative</span><span class=\"w\"> </span><span class=\"n\">mining</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">_</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_targets</span><span class=\"p\">.</span><span class=\"k\">size</span><span class=\"p\">()</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">batch_conf</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_preds</span><span class=\"p\">.</span><span class=\"k\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">self</span><span class=\"p\">.</span><span class=\"n\">num_classes</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">cls_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">F</span><span class=\"p\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">batch_conf</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">cls_targets</span><span class=\"p\">.</span><span class=\"k\">view</span><span class=\"p\">(</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"n\">ignore_index</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">reduction</span><span class=\"o\">=</span><span class=\"s1\">&#39;none&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">cls_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_loss</span><span class=\"p\">.</span><span class=\"k\">view</span><span class=\"p\">(</span><span class=\"n\">batch_size</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"n\">Hard</span><span class=\"w\"> </span><span class=\"n\">Negative</span><span class=\"w\"> </span><span class=\"n\">Mining</span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"k\">filter</span><span class=\"w\"> </span><span class=\"k\">out</span><span class=\"w\"> </span><span class=\"n\">pos</span><span class=\"w\"> </span><span class=\"n\">boxes</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">pos</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_targets</span><span class=\"w\"> </span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">now</span><span class=\"p\">.</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">pos_cls_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_loss</span><span class=\"o\">[</span><span class=\"n\">pos</span><span class=\"o\">]</span>\n",
       "<span class=\"w\">        </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"ow\">In</span><span class=\"w\"> </span><span class=\"n\">OHEM</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">we</span><span class=\"w\"> </span><span class=\"n\">have</span><span class=\"w\"> </span><span class=\"k\">to</span><span class=\"w\"> </span><span class=\"k\">select</span><span class=\"w\"> </span><span class=\"k\">only</span><span class=\"w\"> </span><span class=\"n\">those</span><span class=\"w\"> </span><span class=\"n\">background</span><span class=\"w\"> </span><span class=\"n\">labels</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"n\">that</span><span class=\"w\"> </span><span class=\"n\">have</span><span class=\"w\"> </span><span class=\"n\">been</span><span class=\"w\"> </span><span class=\"n\">failed</span><span class=\"w\"> </span><span class=\"k\">with</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">very</span><span class=\"w\"> </span><span class=\"n\">high</span><span class=\"w\"> </span><span class=\"n\">margin</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">lets</span><span class=\"w\"> </span><span class=\"n\">we</span><span class=\"w\"> </span><span class=\"n\">will</span><span class=\"w\"> </span><span class=\"nf\">choose</span><span class=\"w\"> </span><span class=\"n\">three</span><span class=\"w\"> </span><span class=\"n\">times</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">negpos_ratio</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"k\">object</span><span class=\"w\"> </span><span class=\"n\">labels</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">&gt;=</span><span class=\"mi\">1</span><span class=\"p\">)).</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"k\">To</span><span class=\"w\"> </span><span class=\"n\">paly</span><span class=\"w\"> </span><span class=\"n\">around</span><span class=\"w\"> </span><span class=\"n\">background</span><span class=\"w\"> </span><span class=\"n\">labels</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">let</span><span class=\"s1\">&#39;s make zero loss to object labels.</span>\n",
       "<span class=\"s1\">        cls_loss[pos] = 0 </span>\n",
       "<span class=\"s1\">        </span>\n",
       "<span class=\"s1\">        # Let&#39;</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"n\">find</span><span class=\"w\"> </span><span class=\"n\">indices</span><span class=\"w\"> </span><span class=\"k\">of</span><span class=\"w\"> </span><span class=\"n\">decreasing</span><span class=\"w\"> </span><span class=\"k\">order</span><span class=\"w\"> </span><span class=\"k\">of</span><span class=\"w\"> </span><span class=\"n\">loss</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">which</span><span class=\"w\"> </span><span class=\"n\">ground</span><span class=\"w\"> </span><span class=\"n\">truth</span><span class=\"w\"> </span><span class=\"k\">is</span><span class=\"w\"> </span><span class=\"n\">background</span><span class=\"p\">).</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span><span class=\"n\">_</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">loss_idx</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_loss</span><span class=\"p\">.</span><span class=\"n\">sort</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">descending</span><span class=\"o\">=</span><span class=\"k\">True</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"k\">If</span><span class=\"w\"> </span><span class=\"n\">we</span><span class=\"w\"> </span><span class=\"n\">sort</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"ow\">in</span><span class=\"w\"> </span><span class=\"n\">increasing</span><span class=\"w\"> </span><span class=\"k\">order</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">above</span><span class=\"w\"> </span><span class=\"n\">indices</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">indices</span><span class=\"w\"> </span><span class=\"n\">correspond</span><span class=\"w\"> </span><span class=\"k\">to</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">sorting</span><span class=\"w\"> </span><span class=\"n\">will</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"n\">give</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">ranking</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">along</span><span class=\"w\"> </span><span class=\"n\">dimension</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">original</span><span class=\"w\"> </span><span class=\"n\">loss</span><span class=\"w\"> </span><span class=\"n\">matrix</span><span class=\"p\">.</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span><span class=\"n\">_</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">idx_rank</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">loss_idx</span><span class=\"p\">.</span><span class=\"n\">sort</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"n\">Let</span><span class=\"s1\">&#39;s understand by example. As all operations are along axis 1, taking 1-d example will be sufficient.</span>\n",
       "\n",
       "<span class=\"s1\">        # cls_loss = [5, 2, 9, 6,  8]</span>\n",
       "\n",
       "<span class=\"s1\">        # _, loss_idx = cls_loss.sort(descending=True)</span>\n",
       "<span class=\"s1\">        # loss_idx = [2, 4, 3, 0, 1]</span>\n",
       "\n",
       "<span class=\"s1\">        # _, idx_rank = loss_idx.sort()</span>\n",
       "<span class=\"s1\">        # idx_rank = [3, 4, 0, 2, 1]</span>\n",
       "<span class=\"s1\">        </span>\n",
       "<span class=\"s1\">        # Have a look, idx_rank has the ranking of cls_loss.</span>\n",
       "\n",
       "<span class=\"s1\">        negpos_ratio = 3</span>\n",
       "<span class=\"s1\">        </span>\n",
       "<span class=\"s1\">        # We have decided we will take the negative class count three times of the positive class. </span>\n",
       "\n",
       "<span class=\"s1\">        # If we do it blindly, in the case of not a positive class in the image, we will end up missing </span>\n",
       "<span class=\"s1\">        # all the negative class also. So let&#39;</span><span class=\"n\">s</span><span class=\"w\"> </span><span class=\"n\">clamp</span><span class=\"w\"> </span><span class=\"n\">minimum</span><span class=\"w\"> </span><span class=\"k\">to</span><span class=\"w\"> </span><span class=\"mf\">1.</span><span class=\"w\"> </span>\n",
       "<span class=\"w\">        </span><span class=\"err\">#</span><span class=\"w\"> </span><span class=\"n\">Although</span><span class=\"w\"> </span><span class=\"n\">maximum</span><span class=\"w\"> </span><span class=\"n\">clamping</span><span class=\"w\"> </span><span class=\"k\">is</span><span class=\"w\"> </span><span class=\"ow\">not</span><span class=\"w\"> </span><span class=\"n\">required</span><span class=\"w\"> </span><span class=\"n\">here</span><span class=\"p\">,</span><span class=\"w\">  </span><span class=\"n\">let</span><span class=\"w\"> </span><span class=\"n\">fix</span><span class=\"w\"> </span><span class=\"k\">to</span><span class=\"w\"> </span><span class=\"n\">maximum</span><span class=\"w\"> </span><span class=\"k\">index</span><span class=\"p\">.</span><span class=\"w\"> </span>\n",
       "\n",
       "<span class=\"w\">        </span><span class=\"n\">num_neg</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">torch</span><span class=\"p\">.</span><span class=\"n\">clamp</span><span class=\"p\">(</span><span class=\"n\">negpos_ratio</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">num_pos</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nf\">min</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"nf\">max</span><span class=\"o\">=</span><span class=\"n\">pos</span><span class=\"p\">.</span><span class=\"k\">size</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"w\">        </span><span class=\"n\">neg</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">idx_rank</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">num_neg</span><span class=\"p\">.</span><span class=\"n\">expand_as</span><span class=\"p\">(</span><span class=\"n\">idx_rank</span><span class=\"p\">)</span>\n",
       "<span class=\"w\">        </span><span class=\"n\">neg_cls_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">cls_loss</span><span class=\"o\">[</span><span class=\"n\">neg</span><span class=\"o\">]</span>\n",
       "\n",
       "<span class=\"w\">        </span><span class=\"n\">cls_loss</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">pos_cls_loss</span><span class=\"p\">.</span><span class=\"nf\">sum</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">neg_cls_loss</span><span class=\"p\">.</span><span class=\"nf\">sum</span><span class=\"p\">())</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"w\"> </span><span class=\"n\">num_pos</span><span class=\"p\">.</span><span class=\"nf\">sum</span><span class=\"p\">().</span><span class=\"nc\">float</span><span class=\"p\">()</span>\n",
       "<span class=\"w\">       </span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{+w}{       }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{k}{Compute}\\PY{+w}{ }\\PY{n+nf}{max}\\PY{+w}{ }\\PY{n}{conf}\\PY{+w}{ }\\PY{n}{across}\\PY{+w}{ }\\PY{n}{batch}\\PY{+w}{ }\\PY{k}{for}\\PY{+w}{ }\\PY{n}{hard}\\PY{+w}{ }\\PY{n}{negative}\\PY{+w}{ }\\PY{n}{mining}\n",
       "\\PY{+w}{        }\\PY{n}{batch\\PYZus{}size}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{\\PYZus{}}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}targets}\\PY{p}{.}\\PY{k}{size}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{n}{batch\\PYZus{}conf}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}preds}\\PY{p}{.}\\PY{k}{view}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{self}\\PY{p}{.}\\PY{n}{num\\PYZus{}classes}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{n}{cls\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{F}\\PY{p}{.}\\PY{n}{cross\\PYZus{}entropy}\\PY{p}{(}\\PY{n}{batch\\PYZus{}conf}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}targets}\\PY{p}{.}\\PY{k}{view}\\PY{p}{(}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{ignore\\PYZus{}index}\\PY{o}{=}\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{reduction}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}none\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{n}{cls\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}loss}\\PY{p}{.}\\PY{k}{view}\\PY{p}{(}\\PY{n}{batch\\PYZus{}size}\\PY{p}{,}\\PY{+w}{ }\\PY{o}{\\PYZhy{}}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{n}{Hard}\\PY{+w}{ }\\PY{n}{Negative}\\PY{+w}{ }\\PY{n}{Mining}\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{k}{filter}\\PY{+w}{ }\\PY{k}{out}\\PY{+w}{ }\\PY{n}{pos}\\PY{+w}{ }\\PY{n}{boxes}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{pos}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}targets}\\PY{+w}{ }\\PY{o}{\\PYZgt{}}\\PY{+w}{ }\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{+w}{ }\\PY{k}{for}\\PY{+w}{ }\\PY{n}{now}\\PY{p}{.}\n",
       "\\PY{+w}{        }\\PY{n}{pos\\PYZus{}cls\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}loss}\\PY{o}{[}\\PY{n}{pos}\\PY{o}{]}\n",
       "\\PY{+w}{        }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{o+ow}{In}\\PY{+w}{ }\\PY{n}{OHEM}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{we}\\PY{+w}{ }\\PY{n}{have}\\PY{+w}{ }\\PY{k}{to}\\PY{+w}{ }\\PY{k}{select}\\PY{+w}{ }\\PY{k}{only}\\PY{+w}{ }\\PY{n}{those}\\PY{+w}{ }\\PY{n}{background}\\PY{+w}{ }\\PY{n}{labels}\\PY{+w}{ }\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{+w}{ }\\PY{n}{that}\\PY{+w}{ }\\PY{n}{have}\\PY{+w}{ }\\PY{n}{been}\\PY{+w}{ }\\PY{n}{failed}\\PY{+w}{ }\\PY{k}{with}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{n}{a}\\PY{+w}{ }\\PY{n}{very}\\PY{+w}{ }\\PY{n}{high}\\PY{+w}{ }\\PY{n}{margin}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{lets}\\PY{+w}{ }\\PY{n}{we}\\PY{+w}{ }\\PY{n}{will}\\PY{+w}{ }\\PY{n+nf}{choose}\\PY{+w}{ }\\PY{n}{three}\\PY{+w}{ }\\PY{n}{times}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{negpos\\PYZus{}ratio}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{l+m+mi}{3}\\PY{p}{)}\\PY{+w}{ }\\PY{k}{of}\\PY{+w}{ }\\PY{n}{the}\\PY{+w}{ }\\PY{k}{object}\\PY{+w}{ }\\PY{n}{labels}\\PY{+w}{ }\\PY{p}{(}\\PY{o}{\\PYZgt{}=}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{p}{)}\\PY{p}{.}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{k}{To}\\PY{+w}{ }\\PY{n}{paly}\\PY{+w}{ }\\PY{n}{around}\\PY{+w}{ }\\PY{n}{background}\\PY{+w}{ }\\PY{n}{labels}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{let}\\PY{l+s+s1}{\\PYZsq{}s make zero loss to object labels.}\n",
       "\\PY{l+s+s1}{        cls\\PYZus{}loss[pos] = 0 }\n",
       "\\PY{l+s+s1}{        }\n",
       "\\PY{l+s+s1}{        \\PYZsh{} Let\\PYZsq{}}\\PY{n}{s}\\PY{+w}{ }\\PY{n}{find}\\PY{+w}{ }\\PY{n}{indices}\\PY{+w}{ }\\PY{k}{of}\\PY{+w}{ }\\PY{n}{decreasing}\\PY{+w}{ }\\PY{k}{order}\\PY{+w}{ }\\PY{k}{of}\\PY{+w}{ }\\PY{n}{loss}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{which}\\PY{+w}{ }\\PY{n}{ground}\\PY{+w}{ }\\PY{n}{truth}\\PY{+w}{ }\\PY{k}{is}\\PY{+w}{ }\\PY{n}{background}\\PY{p}{)}\\PY{p}{.}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{loss\\PYZus{}idx}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}loss}\\PY{p}{.}\\PY{n}{sort}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{descending}\\PY{o}{=}\\PY{k}{True}\\PY{p}{)}\n",
       "\\PY{+w}{        }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{k}{If}\\PY{+w}{ }\\PY{n}{we}\\PY{+w}{ }\\PY{n}{sort}\\PY{+w}{ }\\PY{p}{(}\\PY{o+ow}{in}\\PY{+w}{ }\\PY{n}{increasing}\\PY{+w}{ }\\PY{k}{order}\\PY{p}{)}\\PY{+w}{ }\\PY{n}{the}\\PY{+w}{ }\\PY{n}{above}\\PY{+w}{ }\\PY{n}{indices}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{indices}\\PY{+w}{ }\\PY{n}{correspond}\\PY{+w}{ }\\PY{k}{to}\\PY{+w}{ }\\PY{n}{the}\\PY{+w}{ }\\PY{n}{sorting}\\PY{+w}{ }\\PY{n}{will}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{n}{give}\\PY{+w}{ }\\PY{n}{a}\\PY{+w}{ }\\PY{n}{ranking}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{along}\\PY{+w}{ }\\PY{n}{dimension}\\PY{+w}{ }\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{+w}{ }\\PY{k}{of}\\PY{+w}{ }\\PY{n}{the}\\PY{+w}{ }\\PY{n}{original}\\PY{+w}{ }\\PY{n}{loss}\\PY{+w}{ }\\PY{n}{matrix}\\PY{p}{.}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\\PY{n}{\\PYZus{}}\\PY{p}{,}\\PY{+w}{ }\\PY{n}{idx\\PYZus{}rank}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{loss\\PYZus{}idx}\\PY{p}{.}\\PY{n}{sort}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\\PY{+w}{        }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{n}{Let}\\PY{l+s+s1}{\\PYZsq{}s understand by example. As all operations are along axis 1, taking 1\\PYZhy{}d example will be sufficient.}\n",
       "\n",
       "\\PY{l+s+s1}{        \\PYZsh{} cls\\PYZus{}loss = [5, 2, 9, 6,  8]}\n",
       "\n",
       "\\PY{l+s+s1}{        \\PYZsh{} \\PYZus{}, loss\\PYZus{}idx = cls\\PYZus{}loss.sort(descending=True)}\n",
       "\\PY{l+s+s1}{        \\PYZsh{} loss\\PYZus{}idx = [2, 4, 3, 0, 1]}\n",
       "\n",
       "\\PY{l+s+s1}{        \\PYZsh{} \\PYZus{}, idx\\PYZus{}rank = loss\\PYZus{}idx.sort()}\n",
       "\\PY{l+s+s1}{        \\PYZsh{} idx\\PYZus{}rank = [3, 4, 0, 2, 1]}\n",
       "\\PY{l+s+s1}{        }\n",
       "\\PY{l+s+s1}{        \\PYZsh{} Have a look, idx\\PYZus{}rank has the ranking of cls\\PYZus{}loss.}\n",
       "\n",
       "\\PY{l+s+s1}{        negpos\\PYZus{}ratio = 3}\n",
       "\\PY{l+s+s1}{        }\n",
       "\\PY{l+s+s1}{        \\PYZsh{} We have decided we will take the negative class count three times of the positive class. }\n",
       "\n",
       "\\PY{l+s+s1}{        \\PYZsh{} If we do it blindly, in the case of not a positive class in the image, we will end up missing }\n",
       "\\PY{l+s+s1}{        \\PYZsh{} all the negative class also. So let\\PYZsq{}}\\PY{n}{s}\\PY{+w}{ }\\PY{n}{clamp}\\PY{+w}{ }\\PY{n}{minimum}\\PY{+w}{ }\\PY{k}{to}\\PY{+w}{ }\\PY{l+m+mf}{1.}\\PY{+w}{ }\n",
       "\\PY{+w}{        }\\PY{err}{\\PYZsh{}}\\PY{+w}{ }\\PY{n}{Although}\\PY{+w}{ }\\PY{n}{maximum}\\PY{+w}{ }\\PY{n}{clamping}\\PY{+w}{ }\\PY{k}{is}\\PY{+w}{ }\\PY{o+ow}{not}\\PY{+w}{ }\\PY{n}{required}\\PY{+w}{ }\\PY{n}{here}\\PY{p}{,}\\PY{+w}{  }\\PY{n}{let}\\PY{+w}{ }\\PY{n}{fix}\\PY{+w}{ }\\PY{k}{to}\\PY{+w}{ }\\PY{n}{maximum}\\PY{+w}{ }\\PY{k}{index}\\PY{p}{.}\\PY{+w}{ }\n",
       "\n",
       "\\PY{+w}{        }\\PY{n}{num\\PYZus{}neg}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{torch}\\PY{p}{.}\\PY{n}{clamp}\\PY{p}{(}\\PY{n}{negpos\\PYZus{}ratio}\\PY{+w}{ }\\PY{o}{*}\\PY{+w}{ }\\PY{n}{num\\PYZus{}pos}\\PY{p}{,}\\PY{+w}{ }\\PY{n+nf}{min}\\PY{o}{=}\\PY{l+m+mi}{1}\\PY{p}{,}\\PY{+w}{ }\\PY{n+nf}{max}\\PY{o}{=}\\PY{n}{pos}\\PY{p}{.}\\PY{k}{size}\\PY{p}{(}\\PY{l+m+mi}{1}\\PY{p}{)}\\PY{+w}{ }\\PY{o}{\\PYZhy{}}\\PY{+w}{ }\\PY{l+m+mi}{1}\\PY{p}{)}\n",
       "\n",
       "\\PY{+w}{        }\\PY{n}{neg}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{idx\\PYZus{}rank}\\PY{+w}{ }\\PY{o}{\\PYZlt{}}\\PY{+w}{ }\\PY{n}{num\\PYZus{}neg}\\PY{p}{.}\\PY{n}{expand\\PYZus{}as}\\PY{p}{(}\\PY{n}{idx\\PYZus{}rank}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{n}{neg\\PYZus{}cls\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{n}{cls\\PYZus{}loss}\\PY{o}{[}\\PY{n}{neg}\\PY{o}{]}\n",
       "\n",
       "\\PY{+w}{        }\\PY{n}{cls\\PYZus{}loss}\\PY{+w}{ }\\PY{o}{=}\\PY{+w}{ }\\PY{p}{(}\\PY{n}{pos\\PYZus{}cls\\PYZus{}loss}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{+w}{ }\\PY{o}{+}\\PY{+w}{ }\\PY{n}{neg\\PYZus{}cls\\PYZus{}loss}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\\PY{+w}{ }\\PY{o}{/}\\PY{+w}{ }\\PY{n}{num\\PYZus{}pos}\\PY{p}{.}\\PY{n+nf}{sum}\\PY{p}{(}\\PY{p}{)}\\PY{p}{.}\\PY{n+nc}{float}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{+w}{       }\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "       # Compute max conf across batch for hard negative mining\n",
       "        batch_size, _ = cls_targets.size()\n",
       "        batch_conf = cls_preds.view(-1, self.num_classes)\n",
       "        cls_loss = F.cross_entropy(batch_conf, cls_targets.view(-1), ignore_index=-1, reduction='none')\n",
       "        cls_loss = cls_loss.view(batch_size, -1)\n",
       "\n",
       "        # Hard Negative Mining\n",
       "        # filter out pos boxes (pos = cls_targets > 0) for now.\n",
       "        pos_cls_loss = cls_loss[pos]\n",
       "        \n",
       "        # In OHEM, we have to select only those background labels (0) that have been failed with \n",
       "        # a very high margin (lets we will choose three times (negpos_ratio = 3) of the object labels (>=1)). \n",
       "        \n",
       "        # To paly around background labels, let's make zero loss to object labels.\n",
       "        cls_loss[pos] = 0 \n",
       "        \n",
       "        # Let's find indices of decreasing order of loss (which ground truth is background). \n",
       "        _, loss_idx = cls_loss.sort(1, descending=True)\n",
       "        \n",
       "        # If we sort (in increasing order) the above indices, indices correspond to the sorting will \n",
       "        # give a ranking (along dimension 1) of the original loss matrix. \n",
       "        _, idx_rank = loss_idx.sort(1)\n",
       "        \n",
       "        # Let's understand by example. As all operations are along axis 1, taking 1-d example will be sufficient.\n",
       "\n",
       "        # cls_loss = [5, 2, 9, 6,  8]\n",
       "\n",
       "        # _, loss_idx = cls_loss.sort(descending=True)\n",
       "        # loss_idx = [2, 4, 3, 0, 1]\n",
       "\n",
       "        # _, idx_rank = loss_idx.sort()\n",
       "        # idx_rank = [3, 4, 0, 2, 1]\n",
       "        \n",
       "        # Have a look, idx_rank has the ranking of cls_loss.\n",
       "\n",
       "        negpos_ratio = 3\n",
       "        \n",
       "        # We have decided we will take the negative class count three times of the positive class. \n",
       "\n",
       "        # If we do it blindly, in the case of not a positive class in the image, we will end up missing \n",
       "        # all the negative class also. So let's clamp minimum to 1. \n",
       "        # Although maximum clamping is not required here,  let fix to maximum index. \n",
       "\n",
       "        num_neg = torch.clamp(negpos_ratio * num_pos, min=1, max=pos.size(1) - 1)\n",
       "\n",
       "        neg = idx_rank < num_neg.expand_as(idx_rank)\n",
       "        neg_cls_loss = cls_loss[neg]\n",
       "\n",
       "        cls_loss = (pos_cls_loss.sum() + neg_cls_loss.sum()) / num_pos.sum().float()\n",
       "       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(data=inspect.getsource(DetectionLoss)[1597:3835])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final loss will be a weighted sum of localization and classification loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span> \n",
       "        # The magnitude of cross-entropy loss is much more than L2, L1, and smooth L1. \n",
       "        # So it is better to take a weighted loss. Here we have chosen twenty times of \n",
       "        # lower magnitude loss and one time of higher magnitude loss.\n",
       "\n",
       "        return 20 * loc_loss, cls_loss\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       " \n",
       "        \\PYZsh{} The magnitude of cross\\PYZhy{}entropy loss is much more than L2, L1, and smooth L1. \n",
       "        \\PYZsh{} So it is better to take a weighted loss. Here we have chosen twenty times of \n",
       "        \\PYZsh{} lower magnitude loss and one time of higher magnitude loss.\n",
       "\n",
       "        return 20 * loc\\PYZus{}loss, cls\\PYZus{}loss\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       " \n",
       "        # The magnitude of cross-entropy loss is much more than L2, L1, and smooth L1. \n",
       "        # So it is better to take a weighted loss. Here we have chosen twenty times of \n",
       "        # lower magnitude loss and one time of higher magnitude loss.\n",
       "\n",
       "        return 20 * loc_loss, cls_loss"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Code(data=inspect.getsource(DetectionLoss)[3835:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
